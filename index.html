<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <div class="container">
    <h1>
        Online safety laws unsatisfactory, minister says
    </h1>
    <p class="author"> <b> Kate Whannel</b><br>
        Political reporter
    </p>
    <img src="kisu1.webp" alt="Kissa">
    <p>
        UK laws on internet safety are "very uneven" and "unsatisfactory", Technology Secretary Peter Kyle has said, following calls from campaigners to tighten the rules.

        On Saturday, Ian Russell, the father of Molly Russell, who took her own life at 14 after seeing harmful content online, said the UK was "going backwards" on the issue.
        
        In a letter to the PM, Mr Russell argued that the Online Safety Act, which aims to force tech giants to take more responsibility for their sites' content, needed fixing and said a "duty of care" should be imposed on the firms.
        
        Speaking to the BBC's Laura Kuenssberg, Kyle expressed his "frustration" with the Act, which was passed by the previous Conservative government in 2023.
        
        The Conservative government had originally included in the legislation plans to compel social media companies to remove some "legal-but-harmful" content, such as posts promoting eating disorders.
        
        However the proposal triggered a backlash from critics, including the current Conservative leader Kemi Badenoch, who were concerned it could lead to censorship.
        
        In July 2022, Badenoch, who was not then a minister, said the bill was in "no fit state to become law" adding: "We should not be legislating for hurt feelings."
        
        Another Conservative MP, David Davis, said it risked "the biggest accidental curtailment of free speech in modern history".
        
        The plan was dropped for adult social media users and instead companies were required to give users more control to filter out content they did not want to see. The law still expects companies to protect children from legal-but-harmful content.
        
        Kyle said the section on legal-but-harmful content had been taken out of the bill adding: "So I inherited a landscape where we have a very uneven, unsatisfactory legislative settlement."
        
        He did not commit to making changes to the current legislation but said he was "very open-minded" on the subject.
        
        He also said the act contained some "very good powers" he was using to "assertively" tackle new safety concerns and that in the coming months ministers would get the powers to make sure online platforms were providing age-appropriate content.
        
        Companies that did not comply with the law would face "very strident" sanctions, he said.
        
        Following the interview, a Whitehall source told the BBC the government was not planning to repeal the Online Safety Act, or pass a second act, but to work within what ministers believe are its limitations.
        
        Ministers are not ruling out further legislation but wanted "to be agile and quick" to keep up with fast-moving trends, a source said.
        
        In his letter, Ian Russell argued that "ominous" changes in the tech industry put greater pressure on the government to act.

        He said Mark Zuckerberg, the boss of Meta which owns Facebook and Instagram, and Elon Musk, owner of the social media site X, were "at the leading edge of a wholesale recalibration of the industry".

        He accused Zuckerberg of moving away from safety towards a "laissez-faire, anything-goes model" and "back towards the harmful content that Molly was exposed to".

        Earlier this week, Zuckerberg said Meta would be getting rid of fact checkers, and instead adopt a system â€“ already introduced by X - of allowing users to add "community notes" to social media posts they deemed to be untrue.

        This marked a change from Meta's previous approach, introduced in 2016, whereby third party moderators would check posts on Facebook and Instagram that appeared to be false or misleading.

        Content flagged as inaccurate would be moved lower in users' feeds and accompanied by labels offering viewers more information on the subject.

        Defending the new system, Zuckerberg said moderators were "too politically biased" and it was "time to get back to our roots around free expression".

        The step comes as Meta seeks to improve relations with incoming US President Donald Trump who has previously accused the company of censoring right-wing voices.

        Zuckerberg said the change - which only applies in the US - would mean content moderators would "catch less bad stuff" but would also reduce the number of "innocent" posts being removed.
    </p>

    <p>
        <p> 
            <a href="https://www.bbc.com/"> Back to BBC site</a>
        </p>
    </p>
</div>
</body>
</html>
</body>
</html>
